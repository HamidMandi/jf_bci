function [res]=cvmcPerf(Y,dv,dim,fIdxs,spMx,spKey,decoder)
% compute cross-validated multi-class performance
%
% [res]=cvmcPerf(Y,dv,dim,fIdxs,spMx,spKey)
%
% N.B. dv can have only a *single* trial dimension, though it may have multiple
% sub-problem dimensions, e.g. 1-for sequences + 1-for multi-class
% 
% Inputs:
%  Y    -- [N x 1] trial class labels
%           OR
%          [N x nClass] trial class indicator (-1/0/+1) matrix
%  dv   --[n-d] set of classifier decision values
%  dim -- [3 x 1] indicator of where different types of dimension are in dv:
%          dim(1)       = trD  -- trial dim
%          dim(2:end-1) = spD  -- binary sub-prob dim(s)
%          dim(end)     = fldD -- folds dim
%  fIdxs-- [N x nFolds] set of -1/0/+1 fold membership indicators, as 
%          generated by gennFold/cvtrainKLR ([-ones(N,1)])
%           OR
%          [size(dv,1:max(spD,trD)) or 1) x nFolds] set of -1/0/+1 fold membership indicators
%           N.B. all subproblems must be included or excluded from a fold!
%  spMx -- [size(dv,spD) x nClass] sub-problem to class decoding matrix, 
%                    as generated by mkspMx/lab2ind
%          OR
%          [size(dv,spD) x N x nClass] per-trial sub-problem decoding matrix
%  spKey-- [nClass] key to spMx class columns used to map from spMx to Y ([1:nClass])
%  decoder -- [str] type of multi-class decoder to use; 'ml' or 'pairwise' ([])
%  discretePred -- [2x1 bool] discretise the outputs                     ([true false])
% Output:
%  mcres   -- results structure with
%  |.fold -- per fold results
%  |     |.di         -- dimInfo structure describing the contents of these 
%  |     |               matrices
%  |     |.trnmcconf  -- training set multi-class confusion matrix
%  |     |.trncr      -- training set multi-class classification rate
%  |     |.tstmcconf  -- testing set multi-class confusion matrix
%  |     |.tstcr      -- testing set multi-class classification rate
%  |.trnmcconf-- ave over folds, training set confusion matrix
%  |.trncr    -- ave over folds, training set multi-class classification rate
%  |.trncr_se -- std-error of ave training set multi-class classification rate
%  |.tstmcconf-- ave over folds, training set confusion matrix
%  |.tstcr    -- ave over folds, testing set multi-class classification rate
%  |.tstcr_se -- std-error of ave testing set multi-class classification rate
%  |.di       -- dimInfo structure describing contents of the fold ave matrices
%

% compute the multi-class performance if wanted
if ( nargin < 4 ) fIdxs=[]; end;
if ( nargin < 5 ) spMx=[]; end;
if ( nargin < 6 ) spKey=[]; end;
if ( nargin < 7 ) decoder=[]; end;
if ( nargin < 8 ) discretePred=[true false]; end;
dim(dim<0)=ndims(dv)+1+dim(dim<0);
if ( numel(dim)<3 ) dim(3)=ndims(dv)+1; end; dim(dim<=0)=dim(dim<=0)+ndims(dv)+1;
trD=dim(1); spD=dim(2:end-1); spD=spD(:)'; fldD=dim(end); 
dvsz=size(dv); dvsz(end+1:max(dim))=1;

% convert label lists to correct label-indicators
if ( sum(size(Y)>1)==1 ) 
   Yl=Y;
   Y=lab2ind(Y(:),spKey,[],[],0); 
end;

% check the size of foldIdxs and add in a subProb dim if not already there
nfldD = numel(spD)+numel(trD)+1;
if( ndims(fIdxs)<nfldD )
   fldSz=size(fIdxs);
   if ( sum(spD>trD)>0 ) % add singleton after
     fIdxs = reshape(fIdxs,[fldSz(1:end-1) 1 fldSz(end)]);
   else % add singlention before trD
     npreSpD = sum(spD<trD);
     fIdxs = reshape(fIdxs,[fldSz(1:npreSpD-1) 1 fldSz(npreSpD:end)]);  
   end
end 


% check foldIdxs is ok, remove any per-subProb fold info, and reshape to [N x nFold]
if ( isempty(fIdxs) || numel(fIdxs)==1 ) fIdxs=ones([dvsz(trD) 1]); end; %size(Y,1),1);
if ( ndims(fIdxs)>2 )
   badTrn=false; badTst=false;
   for d=1:numel(spD); % check that we don't have per-sp foldIdx
      if ( any(any(diff(fIdxs<0,[],spD(d))~=0)) ) badTrn=true; end;
      if ( any(any(diff(fIdxs>0,[],spD(d))~=0)) ) badTst=true; end;
   end
   if(badTrn) warning('mcPerf:dodgyTrainingFolds','All sub-probs should have same training-fold membership');end;
   if(badTst) error('All sub-probs *must* have same testing-fold membership'); end;
   % squash multiple spDims in foldIdxs into 1 dim [N x prod(size(dv,spD)) x nFolds]
   idx={}; for d=1:ndims(fIdxs); idx{d}=1:size(fIdxs,d); end; [idx{[spD end+1:max(spD)]}]=deal(1);
   szfIdxs=size(fIdxs);fIdxs=reshape(fIdxs(idx{:}),szfIdxs(setdiff(1:ndims(fIdxs),spD))); % remove spD
end

% preallocate the matrices to hold the results
res=struct();
%mcconfsz=dvsz;  mcconfsz(dim(1))=size(Y,2).^2 ; mcconfsz(dim(2:end))=1;
%mcconfsz=[size(Y,2).^2 dvsz(setdiff(1:end,dim)) dvsz(dim(end))];
mcconfsz=[size(Y,2).^2 dvsz(setdiff(1:end,dim)) dvsz(dim(end))];
res.fold.trnmcconf=zeros(mcconfsz,'single');
res.fold.tstmcconf=zeros(mcconfsz,'single');
res.fold.trncr=zeros([1 mcconfsz(2:end)],'single');
res.fold.tstcr=zeros([1 mcconfsz(2:end)],'single');
res.trnmcconf=zeros(mcconfsz(1:end-1),'single');
res.tstmcconf=zeros(mcconfsz(1:end-1),'single');
res.trncr=zeros([1 mcconfsz(2:end-1)],'single');
res.trncr_se=zeros([1 mcconfsz(2:end-1)],'single');
res.tstcr=zeros([1 mcconfsz(2:end-1)],'single');
res.trncr_se=zeros([1 mcconfsz(2:end-1)],'single');
nFolds=size(dv,fldD);


if( ndims(spMx)<=numel(spD)+1 ) 
   pc = dv2pred(dv,spD,spMx,decoder,discretePred);     % pred-class [N x nCls x nCs x nFold]
else
   pc = dv2pred(dv,spD,spMx,decoder,discretePred,trD); % per-trial decoder
end
idx={};for d=1:max([ndims(pc),spD(:)',trD,fldD]); idx{d}=1:size(pc,d); end;
yidx=[]; for d=1:ndims(Y); yidx{d}=1:size(Y,d); end;
mcconfIdx={}; for d=1:numel(mcconfsz); mcconfIdx{d}=1:mcconfsz(d); end;
for foldi=1:nFolds;
   idx{fldD}=foldi;  mcconfIdx{end}=foldi;
   idx{trD}=find(fIdxs(:,foldi)<0); % get the training trials
   res.fold.trnmcconf(mcconfIdx{:})=pred2conf(Y(idx{trD},:),pc(idx{:}),[trD spD(1)]);
   idx{trD}=find(fIdxs(:,foldi)>0); % get the testing trials
   res.fold.tstmcconf(mcconfIdx{:})=pred2conf(Y(idx{trD},:),pc(idx{:}),[trD spD(1)]);
end
res.fold.trncr= conf2loss(res.fold.trnmcconf);%,trD,'cr');
res.fold.tstcr= conf2loss(res.fold.tstmcconf);%,trD,'cr');
res.trnmcconf = sum(res.fold.trnmcconf,numel(mcconfsz));%msqueeze(fldD,sum(res.fold.trnmcconf,fldD));
res.tstmcconf = sum(res.fold.tstmcconf,numel(mcconfsz));%msqueeze(fldD,sum(res.fold.tstmcconf,fldD));
res.trncr     = conf2loss(res.trnmcconf);%,trD,'cr');
res.trncr_se  = sqrt(abs(sum(res.fold.trncr.^2,numel(mcconfsz))/nFolds-(res.trncr.^2))/nFolds);%sqrt(abs(msqueeze(fldD,sum(res.fold.trncr.^2,fldD))/nFolds-(res.trncr.^2))/nFolds);
res.tstcr     = conf2loss(res.tstmcconf);%,trD,'cr');
res.tstcr_se  = sqrt(abs(sum(res.fold.tstcr.^2,numel(mcconfsz))/nFolds-(res.tstcr.^2))/nFolds);%sqrt(abs(msqueeze(fldD,sum(res.fold.tstcr.^2,fldD))/nFolds-(res.tstcr.^2))/nFolds);

return;

%--------------------------------------------------------------------------------
function testCase()
L=4;
Yl=floor(rand(100,1)*L);
Y =lab2ind(Yl);
fIdxs=gennFold(Y,10);
dv=randn([size(Y) 10]);
[res]=cvmcPerf(Y,dv,[1 2 3],fIdxs);


% test mc performance
[X,Y]=mkMultiClassTst([-1 1; 1 1; 0 0],[400 400 400],[.3 .3; .3 .3; .2 .2],[],[1 2 3]);
labScatPlot(X,Y)

% 1vR
[sp,spDesc]=mc2binSubProb(unique(Y),'1vR');
Yind=lab2ind(Y);
Ysp=lab2ind(Y,sp);
res=cvtrainKLR(X,Ysp,10.^[-3:3],10,'linear','keyY',spDesc,'spType','1vR');
% now extract the multi-class per-fold/C performance from the recorded info
mcres=cvmcPerf(Yind,res.fold.f,...
               [1 n2d(res.fold.di,'SubProb') n2d(res.fold.di,'Fold')],...
               res.fold.di(3).info.fIdxs,res.di(3).info.spType);


% 1v1
[sp,spDesc]=mc2binSubProb(unique(Y),'1v1');
Yind=lab2ind(Y);
Ysp=lab2ind(Y,sp);
res=cvtrainKLR(X,Ysp,10.^[-3:3],10,'linear','keyY',spDesc,'spType','1v1');
% now extract the multi-class per-fold/C performance from the recorded info
mcres=cvmcPerf(Yind,res.fold.f,...
               [1 n2d(res.fold.di,'SubProb') n2d(res.fold.di,'Fold')],...
               res.fold.di(3).info.fIdxs,res.di(3).info.spType);

% sequence decoding -- with increasing sequence lengths
Yl=single([z.Ydi(n2d(z.Ydi,'letter')).extra.marker])'; % get the sequence label
spKey=z.Ydi(n2d(z.Ydi,'letter')).info.spKey;
foldIdxs=shiftdim(any(z.foldIdxs<0,n2d(z.di,'epoch')));foldIdxs=-(2*foldIdxs-1);% make per-letter fold guide
foldIdxs(shiftdim(all(z.foldIdxs==0,n2d(z.di,'epoch'))))=0; % perserve excluded also
Y = lab2ind(Yl,spKey);
% [ nEp x nLet x nClass ]
spMx=cat(3,z.di(n2d(z.di,'letter')).extra.flipgrid);spMx=permute(spMx,[2 3 1]);spMx(spMx==0)=-1;
nBits=11:11:size(z.X,n2d(z.di,'epoch'));
for ni=1:numel(nBits);
   spMxi=spMx; spMxi(nBits(ni)+1:end,:)=0;  % zero out ignored bits
   mcres(ni)=cvmcPerf(Yl,z.X,[n2d(z.di,'letter') n2d(z.di,'epoch') n2d(z.di,'fold')],foldIdxs,spMxi,spKey);
end

% multi-class sequence decoding -- with increasing sequence lengths


% merge the mult-class results into the bin set.
res.fold.trnmc = mcres.fold.trnmc;
res.fold.tstmc = mcres.fold.tstmc;
res.fold.trnmcconf = mcres.fold.trnmcconf;
res.fold.tstmcconf = mcres.fold.tstmcconf;
res.trnmc = mcres.trnmc;
res.tstmc = mcres.tstmc;
res.trnmcconf = mcres.trnmcconf;
res.tstmcconf = mcres.tstmcconf;

% test the multi-class sequence decoding
z=load('mcseq_res');
res=z.prep(end).info.res;
dim=n2d(z,{'epoch' 'seq'});
Ydi=z.Ydi;
X=z.X;
szX=size(z.X);

%1- compute a non-sequence performance
Yl=single(cat(2,Ydi(dim(end)).extra.marker)); 
spType=Ydi(n2d(Ydi,'subProb')).info.spType; 
spMx=Ydi(n2d(Ydi,'subProb')).info.spMx;
% record true labels for mc-perf
spD=n2d(z,'subProb'); fldD=n2d(z,'fold');
% build a full sized fold guide
fIdxs=z.foldIdxs;
if( size(Yl,1)>1 ) % n-d Yl, so ensure is a full-sized fIdxs
   szYl=size(Yl); szfIdxs=size(fIdxs);
   fIdxs=repmat(fIdxs,[szYl./szfIdxs(1:ndims(Yl)) ones(numel(szfIdxs)-ndims(Yl),1)]);   
end
% N.B. ignores multiple trDims, so much reshape to: [Nx1] and [N x nFold]
mcres=cvmcPerf(Yl(:),reshape(z.X,[prod(szX(1:2)),szX(3:end)]),[1 spD fldD],...
               reshape(fIdxs,[],size(fIdxs,ndims(fIdxs))),spMx,Ydi(n2d(Ydi,'subProb')).info.spKey);
% use the same entry 10 times
mcres=cvmcPerf(Yl(:),reshape(z.X(ones(size(z.X,1),1),:,:,:,:),[prod(szX(1:2)),szX(3:end)]),[1 spD fldD],...
               reshape(fIdxs(ones(size(z.X,1),1),:,:,:),[],size(fIdxs,ndims(fIdxs))),spMx,Ydi(n2d(Ydi,'subProb')).info.spKey);
% use the same entry once
mcres=cvmcPerf(Yl(1,:),reshape(z.X(1,:,:,:,:),[prod(szX(2)),szX(3:end)]),[1 spD fldD],...
               reshape(fIdxs(1,:,:,:),[],size(fIdxs,ndims(fIdxs))),spMx,Ydi(n2d(Ydi,'subProb')).info.spKey);
% use the same n-times
n=2;
mcres=cvmcPerf(vec(Yl(ones(n,1),:)),reshape(z.X(ones(n,1),:,:,:,:),[n*prod(szX(2)),szX(3:end)]),[1 spD fldD],...
               reshape(fIdxs(ones(n,1),:,:,:),[],size(fIdxs,ndims(fIdxs))),spMx,Ydi(n2d(Ydi,'subProb')).info.spKey);


% disp the results
fprintf('----------------\n(ave/ mc)\t');
for ci=1:size(mcres.trncr,3);
   fprintf('%0.2f/%0.2f\t',mcres.trncr(:,1,ci),mcres.tstcr(:,1,ci));
end
fprintf('\n');


% now do the same but with only the 1st entry in the sequence
Yl=single(cat(2,z.Ydi(n2d(z.Ydi,'seq')).extra.marker)); % get the sequence label
Ys=shiftdim(Ys(1,:)); % N.B. entire sequence has same label!
spKey=z.Ydi(n2d(z.Ydi,'seq')).info.spKey; % class markers: [nClass]
spMx=z.Ydi(n2d(z.Ydi,'seq')).info.spMx;   % multi-cls/sequence decoding Mx: [nEp x nSp x nClass ]
fIdxs=shiftdim(any(z.foldIdxs<0,n2d(z.di,'epoch')));fIdxs=-(2*foldIdxs-1);% make per-letter fold guide
fIdxs(shiftdim(all(z.foldIdxs==0,n2d(z.di,'epoch'))))=0; % perserve excluded also
clear mcres bpres;
nBits=1:size(z.X,n2d(z.di,'epoch')); ni=1;
for ni=1:numel(nBits);
   %spMxi=spMx; spMxi(nBits(ni)+1:end,:,:)=0;  % zero out ignored epochs
   spMxi=spMx; spMxi([1:nBits(ni)-1 nBits(ni)+1:end],:,:)=0;  % zero out ignored epochs
   mcres(ni)=cvmcPerf(Ys,z.X,n2d(z.di,{'seq' 'epoch' 'subProb' 'fold'}),fIdxs,spMxi,spKey);
   
   spMxi=spMx(nBits(ni),:,:); %Ys=shiftdim(Ys(nBits(ni),:,:));
   mcres2(ni)=cvmcPerf(Ys,z.X(nBits(ni),:,:,:,:,:),n2d(z.di,{'seq' 'epoch' 'subProb' 'fold'}),fIdxs,spMxi,spKey);
   
   spMxi=shiftdim(spMx(nBits(ni),:,:));
   mcres(ni)=cvmcPerf(Ys,shiftdim(sum(z.X(1:nBits(ni),:,:,:,:,:),1)),n2d(z.di,{'seq' 'subProb' 'fold'})-1,fIdxs,spMxi,spKey);   
end
z.prep(end).info.res.mcres = mcres; % store the results
z.prep(end).info.res.bpres = bpres; % store the binary problem sequence decoding results

% display the results
trn=agetfield(z.prep(end).info.res.mcres,'trncr');
tst=agetfield(z.prep(end).info.res.mcres,'tstcr');
fprintf('Multi-class sequence decoding\n');
fprintf('Cols=Hyperparamters, Rows=SequenceLength\n');
trn=squeeze(trn); tst=squeeze(tst);
for ri=1:size(trn,1); 
   fprintf('%2d)\t',nBits(ri)); fprintf('%.02f/%.02f\t',[trn(ri,:);tst(ri,:)]); fprintf('\n'); 
end;


%    % display the results
%    trn=agetfield(mcres2,'trncr');
%    tst=agetfield(mcres2,'tstcr');
%    fprintf('Multi-class sequence decoding\n');
%    fprintf('Cols=Hyperparamters, Rows=SequenceLength\n');
%    trn=squeeze(trn); tst=squeeze(tst);
%    for ri=1:size(trn,1); 
%       fprintf('%2d)\t',nBits(ri)); fprintf('%.02f/%.02f\t',[trn(ri,:);tst(ri,:)]); fprintf('\n'); 
%    end;

%    % display the results
%    trn=agetfield(mcres3,'trncr');
%    tst=agetfield(mcres3,'tstcr');
%    fprintf('Multi-class sequence decoding\n');
%    fprintf('Cols=Hyperparamters, Rows=SequenceLength\n');
%    trn=squeeze(trn); tst=squeeze(tst);
%    for ri=1:size(trn,1); 
%       fprintf('%2d)\t',nBits(ri)); fprintf('%.02f/%.02f\t',[trn(ri,:);tst(ri,:)]); fprintf('\n'); 
%    end;
